{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=4.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, _children=(), _op=\"\", label=\"\"):\n",
    "        self.data = data; \n",
    "        self.grad = 0.0;\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label;\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "    def __add__(self, other):\n",
    "        out = Value(self.data + other.data, (self, other), \"+\");\n",
    "        return out;\n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.data * other.data, (self, other), \"*\");\n",
    "        return out;\n",
    "a = Value(2.0, label=\"a\");\n",
    "b = Value(-3.0, label=\"b\");\n",
    "c = Value(10.0, label=\"c\");\n",
    "e = a * b; e.label = \"e\"\n",
    "d = e + c; d.label = \"d\"\n",
    "f = Value(-2.0, label=\"f\")\n",
    "L = d * f; L.label = \"L\"\n",
    "L\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropigation, we want to know the derivative of our LOSS in terms of different values that we want to minimize or maximize.\n",
    "Typically the \"LEAF NODES\" or weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L = d * f\n",
    "dL/dd = ? f \n",
    "\n",
    "product rule:\n",
    "\n",
    "dL/dd(d * f) = d*f' + f*d'  \n",
    "              d * d/dd(f) + f * d/dd(d)\n",
    "              d * 0  + f * 1\n",
    "              0 + f\n",
    "              f \n",
    "also:\n",
    "((f(x+h) - f(x)/h))/h\n",
    "((d+h)*f - d * f) /h\n",
    "(d * f + h * f - d * f) / h\n",
    "(h * f ) / h\n",
    "= f\n",
    "dL/dd = f; f is -2.0\n",
    "dL/df = d; d is e + c;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial thought:\n",
    "Chain rule:\n",
    "dL/dc = dL/dd * dd/dc\n",
    "        \n",
    "dd/dc = e + c\n",
    "    dd/dc(e) + dd/dc(c)\n",
    "    0 + 1\n",
    "dd/de = 1\n",
    "video follow:\n",
    "    dd/dc ?\n",
    "    d =  e + c\n",
    "    dd/dc = 1\n",
    "\n",
    "    (f(x+h) -  f(x)) / h\n",
    "    ((c+h + e) - (c+e))/h\n",
    "    (c+h+e-c-e)/h\n",
    "    (c-c+e-e+h)/h\n",
    "    (h)/h\n",
    "    (1)\n",
    "    similarly:\n",
    "        dd/de = 1.0\n",
    "        if a car travels 4x faster than a a bike\n",
    "        if a bike travels 2x faster than walking man\n",
    "        than a car is 4 * 2 faster than a walking man\n",
    "    WANT:\n",
    "        dL/dc = dL / dd * dd/dc\n",
    "    KNOW:\n",
    "        dL/dd\n",
    "        dd/dc\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thought:\n",
    "\n",
    "    dL/de = -2.0\n",
    "\n",
    "    dL/da = dL/de * de/da\n",
    "    dl/db = dL/de * de/db\n",
    "\n",
    "    de/da = a * b\n",
    "            a*b' + a'b\n",
    "            a*d/da(b) + d/da(a)*b\n",
    "            a * 0 + 1 *b\n",
    "            b\n",
    "            similarly a for de/db\n",
    "    de/da = b\n",
    "    de/db = a\n",
    "\n",
    "    dL/da = -2.0 * b; or -2.0 * 3.0\n",
    "    dL/db = -2.0 * a; or -2.0 * 2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual backprop values:\n",
    "    f.grad = 4.0\n",
    "\n",
    "    d.grad = -2.0\n",
    "\n",
    "    c.grad = -2.0\n",
    "\n",
    "    e.grad = -2.0\n",
    "\n",
    "    a.grad = -2.0 * 3.0\n",
    "    \n",
    "    b.grad = -2.0 * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.000000000021544\n"
     ]
    }
   ],
   "source": [
    "def lol():\n",
    "    h = 0.0001\n",
    "    a = Value(2.0, label=\"a\");\n",
    "    b = Value(-3.0, label=\"b\");\n",
    "    c = Value(10.0, label=\"c\");\n",
    "    e = a * b; e.label = \"e\"\n",
    "    d = e + c; d.label = \"d\"\n",
    "    f = Value(-2.0, label=\"f\")\n",
    "    L = d * f; L.label = \"L\"\n",
    "    L1 = L.data\n",
    "\n",
    "    a = Value(2.0, label=\"a\");\n",
    "    b = Value(-3.0, label=\"b\");\n",
    "    c = Value(10.0, label=\"c\");\n",
    "    e = a * b; e.label = \"e\"\n",
    "    d = e + c; d.label = \"d\"\n",
    "    f = Value(-2.0, label=\"f\")\n",
    "    L = d * f; L.label = \"L\"\n",
    "    L2 = L.data\n",
    "    print((L2 - L1)/h)\n",
    "lol()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
